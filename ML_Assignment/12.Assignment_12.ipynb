{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac216006-b32a-4930-9796-5daafa8d0037",
   "metadata": {},
   "source": [
    "1. What is prior probability ? Give an example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947bced5-c496-4575-87f6-a341b169bb82",
   "metadata": {},
   "source": [
    "Ans: Prior probability shows the likelihood of an outcome in a given dataset. For example, in the mortgage case, P(Y) is the default rate on a home mortgage, which is 2%. P(Y|X) is called the conditional probability, which provides the probability of an outcome given the evidence, that is, when the value of X is known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0fff1-28ed-49fa-8172-1f8d388ae149",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd231f72-8adc-4ebb-8b06-b9b8a62f58bf",
   "metadata": {},
   "source": [
    "2. What is posterior probability ? Give an example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e86af-4802-40df-bf9e-6af60fa6f122",
   "metadata": {},
   "source": [
    "Ans:: Posterior probability is a revised probability that takes into account new available information. For example, let there be two urns, urn A having 5 black balls and 10 red balls and urn B having 10 black balls and 5 red balls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929530f-3fc1-4a24-bd8a-3c968bd4c81f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc58a2e-fff3-456f-8a54-f5dc88ca3219",
   "metadata": {},
   "source": [
    "3. What is likelihood probability ? Give an example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f793a-2f38-4079-8db3-49f3714222c7",
   "metadata": {},
   "source": [
    "Ans: Likelihood Function in Machine Learning and Data Science is the joint probability distribution(jpd) of the dataset given as a function of the parameter. Think of it as the probability of obtaining the observed data given the parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6700e94-fcf2-427b-8110-a800ad13ba52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af927771-5e28-4f32-844f-d85bf160967f",
   "metadata": {},
   "source": [
    "4. What is Naïve Bayes classifier ? Why is it named so ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fc057-0e09-4408-b1a4-16e0f1a32f40",
   "metadata": {},
   "source": [
    "Ans: Naive Bayes is a simple and powerful algorithm for predictive modeling. Naive Bayes is called naive because it assumes that each input variable is independent. This is a strong assumption and unrealistic for real data; however, the technique is very effective on a large range of complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ade93-7f5f-47e3-9eae-0afc8d808512",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc2ea179-c91f-4195-99ba-b3ac1ab42813",
   "metadata": {},
   "source": [
    "5. What is optimal Bayes classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e633b78-73a9-4674-9c09-dbdd926a2d3c",
   "metadata": {},
   "source": [
    "Ans: The Bayes Optimal Classifier is a probabilistic model that makes the most probable prediction for a new example. Bayes Optimal Classifier is a probabilistic model that finds the most probable prediction using the training data and space of hypotheses to make a prediction for a new data instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9fd38-a5da-4fd7-9ebc-48f1bf51154b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd84a4fa-2e29-4be8-98fe-f5791101bd9a",
   "metadata": {},
   "source": [
    "6. Write any two features of Bayesian learning methods ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50fa64-3f01-47e4-8dc9-9c79d2eb5897",
   "metadata": {},
   "source": [
    "Ans: A probability distribution over observed data for each possible hypothesis. New instances can be classified by combining the predictions of multiple hypotheses, weighted by their probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a9e6a-2dd5-4562-a2aa-7503c9174e8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09781b77-7a88-4f76-8d01-b27d0f6f715e",
   "metadata": {},
   "source": [
    "7. Define the concept of consistent learners ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fd4dc-b376-49d5-8feb-35f77ae1a7ab",
   "metadata": {},
   "source": [
    "Ans: Consistent Learners: A learner L using a hypothesis H and training data D is said to be a consistent learner if it always outputs a hypothesis with zero error on D whenever H contains such a hypothesis. • By definition, a consistent learner must produce a hypothesis in the version space for H given D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c7204-226a-4ff4-94ed-89f966ae1162",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a52fdae-b114-4d4d-a33b-0d9b51efae25",
   "metadata": {},
   "source": [
    "8. Write any two strengths of Bayes classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d38be-1307-47b0-8758-b11eafceb5d4",
   "metadata": {},
   "source": [
    "Ans: This algorithm works quickly and can save a lot of time. Naive Bayes is suitable for solving multi-class prediction problems. If its assumption of the independence of features holds true, it can perform better than other models and requires much less training data.\n",
    "\n",
    "It is simple and easy to implement.\n",
    "It doesn't require as much training data.\n",
    "It handles both continuous and discrete data.\n",
    "It is highly scalable with the number of predictors and data points.\n",
    "It is fast and can be used to make real-time predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b5902-8031-40e4-89c4-51d6e502eb13",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06db9939-f9b5-47ae-85b6-be28ad50f537",
   "metadata": {},
   "source": [
    "9. Write any two weaknesses of Bayes classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea2168-4bc3-4be3-b285-2239b6c5677d",
   "metadata": {},
   "source": [
    "Ans: The greatest weakness of the naïve Bayes classifier is that it relies on an often-faulty assumption of equally important and independent features which results in biased posterior probabilities.\n",
    "\n",
    "If your test data set has a categorical variable of a category that wasn’t present in the training data set, the Naive Bayes model will assign it zero probability and won’t be able to make any predictions in this regard. This phenomenon is called ‘Zero Frequency,’ and you’ll have to use a smoothing technique to solve this problem.\n",
    "This algorithm is also notorious as a lousy estimator. So, you shouldn’t take the probability outputs of ‘predict_proba’ too seriously.\n",
    "It assumes that all the features are independent. While it might sound great in theory, in real life, you’ll hardly find a set of independent features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e2d24-15c0-485d-b77b-60a4dfcdfbce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0909d3b3-7242-41aa-8d2a-75eb964085fd",
   "metadata": {},
   "source": [
    "10. Explain how Naïve Bayes classifier is used for:\n",
    "Text classification\n",
    "Spam filtering\n",
    "Market sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605eaaac-a174-413d-9707-33d08089cd9f",
   "metadata": {},
   "source": [
    "Ans: Naive Bayes Classifier is used for:\n",
    "\n",
    "Text classification:\n",
    "The Naive Bayes classifier is a simple classifier that classifies based on probabilities of events. It is the applied commonly to text classification. With the training set, we can train a Naive Bayes classifier which we can use to automaticall categorize a new sentence.\n",
    "\n",
    "Spam filtering:\n",
    "Naive Bayes classifiers work by correlating the use of tokens (typically words, or sometimes other things), with spam and non-spam e-mails and then using Bayes' theorem to calculate a probability that an email is or is not spam. It is one of the oldest ways of doing spam filtering, with roots in the 1990s.\n",
    "\n",
    "Market sentiment analysis:\n",
    "Market Sentiment analysis is a field dedicated to extracting subjective emotions and feelings from text. One common use of sentiment analysis is to figure out if a text expresses negative or positive feelings. Naive Bayes is a popular algorithm for classifying text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41e0f3-186d-4ddf-8180-a16efa0c9b49",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
